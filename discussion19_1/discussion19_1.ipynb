{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Discussion 19:1: Building a Recommender System with SURPRISE\n",
    "\n",
    "This discussion focuses on exploring additional algorithms with the `Suprise` library to generate recommendations.  Your goal is to identify the optimal algorithm by minimizing the mean squared error using cross validation. You are also going to select a dataset to use from [grouplens](https://grouplens.org/datasets/movielens/) example datasets.  \n",
    "\n",
    "To begin, head over to [grouplens](https://grouplens.org/datasets/movielens/) and examine the different datasets available.  Choose one so that it is easy to create the data as expected in `Surprise` with user, item, and rating information.  Then, compare the performance of at least the `KNNBasic`, `SVD`, `NMF`, `SlopeOne`, and `CoClustering` algorithms to build your recommendations.  For more information on the algorithms see the documentation for the algorithm package [here](https://surprise.readthedocs.io/en/stable/prediction_algorithms_package.html).\n",
    "\n",
    "Share the results of your investigation and include the results of your cross validation and a basic description of your dataset with your peers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, SVD, NMF, KNNBasic, SlopeOne, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define algorithms to test\n",
    "algorithms = {\n",
    "    'SVD': SVD(),\n",
    "    'NMF': NMF(),\n",
    "    'KNNBasic': KNNBasic(),\n",
    "    'SlopeOne': SlopeOne(),\n",
    "    'CoClustering': CoClustering()\n",
    "}\n",
    "\n",
    "# Results dictionary to store performance metrics\n",
    "results = {}\n",
    "\n",
    "# Perform cross-validation for each algorithm\n",
    "for name, algorithm in algorithms.items():\n",
    "    print(f\"Cross-validating {name}...\")\n",
    "    cv_results = cross_validate(algorithm, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        'RMSE_mean': cv_results['test_rmse'].mean(),\n",
    "        'RMSE_std': cv_results['test_rmse'].std(),\n",
    "        'MAE_mean': cv_results['test_mae'].mean(),\n",
    "        'MAE_std': cv_results['test_mae'].std()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert results to DataFrame for easier analysis\n",
    "results_df = pd.DataFrame({\n",
    "    algo: [metrics['RMSE_mean'], metrics['MAE_mean']] \n",
    "    for algo, metrics in results.items()\n",
    "}, index=['RMSE', 'MAE'])\n",
    "\n",
    "# Display the results table\n",
    "print(\"\\nResults Summary:\")\n",
    "print(results_df)\n",
    "\n",
    "# Create bar plot of results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(results))\n",
    "width = 0.35\n",
    "\n",
    "rmse_bars = ax.bar(x - width/2, [results[algo]['RMSE_mean'] for algo in algorithms], \n",
    "                   width, label='RMSE')\n",
    "mae_bars = ax.bar(x + width/2, [results[algo]['MAE_mean'] for algo in algorithms], \n",
    "                  width, label='MAE')\n",
    "\n",
    "ax.set_xlabel('Algorithms')\n",
    "ax.set_ylabel('Error')\n",
    "ax.set_title('Comparison of Recommender Algorithms on MovieLens Dataset')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(algorithms.keys())\n",
    "ax.legend()\n",
    "\n",
    "# Add error values on top of bars\n",
    "def add_labels(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(rmse_bars)\n",
    "add_labels(mae_bars)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find the best algorithm based on RMSE\n",
    "best_algo = min(results.items(), key=lambda x: x[1]['RMSE_mean'])[0]\n",
    "print(f\"\\nThe best algorithm based on RMSE is: {best_algo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
